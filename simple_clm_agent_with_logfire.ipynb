{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b1da9b-f49a-42d5-a911-2a730512770f",
   "metadata": {},
   "source": [
    "# Simple CLM Dataset Search Agent with Logfire\n",
    "\n",
    "This notebook demonstrates a basic agent that can:\n",
    "1. Search for datasets based on topics\n",
    "2. Answer questions about dataset metadata\n",
    "3. Maintain conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341bb20-00e2-482d-b26a-06f174cfcea4",
   "metadata": {},
   "source": [
    "## Step 0: Setup Logfire\n",
    "\n",
    "Run this in your terminal:\n",
    "```bash\n",
    "logfire auth\n",
    "```\n",
    "\n",
    "This opens a browser to authenticate and saves your credentials. You only need to do this once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873f319-76a7-4269-a3cd-d6f2e2a6253d",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6421ab-5386-448c-a951-14b82191cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install python-dotenv ipywidgets pydantic-ai fastmcp openai nest-asyncio logfire opentelemetry-instrumentation-openai opentelemetry-instrumentation-httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a722b4-3a4b-468d-9116-8520f54e52eb",
   "metadata": {},
   "source": [
    "### Step 2: Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f534dd1-20e5-4965-bf57-d3cbe323e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import nest_asyncio\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from fastmcp import Client\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "import logfire\n",
    "\n",
    "\n",
    "import logfire\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "from opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor\n",
    "\n",
    "# Configure Logfire - Cloud only, no local logs\n",
    "logfire.configure(\n",
    "    service_name=\"ndp-clm-agent\",\n",
    ")\n",
    "\n",
    "# Instrument OpenAI and HTTPX after logfire configuration\n",
    "OpenAIInstrumentor().instrument()\n",
    "HTTPXClientInstrumentor().instrument()\n",
    "\n",
    "print(\"‚úì Everything initialized with cloud-only logging\")\n",
    "print(\"‚úì OpenAI API calls will be logged to Logfire cloud\")\n",
    "print(\"‚úì HTTP requests (MCP) will be logged to Logfire cloud\")\n",
    "print(\"‚úì No local logs created\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"‚úì Everything initialized and connected to Logfire cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc49f3-a50d-4060-9243-d1d6b6af4179",
   "metadata": {},
   "source": [
    "### Step 3: API Keys and MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5aca9-3edc-4458-8795-96e71b9108d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Choose your model: \"openai\" or \"nrp\"\n",
    "MODEL = \"openai\"  # Change to \"nrp\" to use Qwen3\n",
    "\n",
    "# Check API keys based on model choice\n",
    "if MODEL == \"openai\":\n",
    "    openai_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not openai_key:\n",
    "        print(\"‚ö†Ô∏è Warning: OPENAI_API_KEY not set!\")\n",
    "    else:\n",
    "        print(\"‚úì OpenAI API key found - Using GPT-4o-mini\")\n",
    "elif MODEL == \"nrp\":\n",
    "    nrp_key = os.getenv('NRP_API_KEY')\n",
    "    if not nrp_key:\n",
    "        print(\"‚ö†Ô∏è Warning: NRP_API_KEY not set!\")\n",
    "    else:\n",
    "        print(\"‚úì NRP API key found - Using Qwen3\")\n",
    "\n",
    "# Initialize MCP client\n",
    "mcp_client = Client(\"https://wenokn.fastmcp.app/mcp\")\n",
    "\n",
    "@dataclass\n",
    "class AgentContext:\n",
    "    current_dataset: Optional[dict] = None\n",
    "\n",
    "print(\"‚úì MCP client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ad519-9e0c-419f-b4c4-fc1c35c991dc",
   "metadata": {},
   "source": [
    "### Step 4: Create Agent with Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41672fb-1f9c-4480-95ea-091ca4528026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_config(model_name: str = \"openai\"):\n",
    "    if model_name == \"nrp\":\n",
    "        os.environ['OPENAI_BASE_URL'] = 'https://ellm.nrp-nautilus.io/v1'\n",
    "        os.environ['OPENAI_API_KEY'] = os.getenv('NRP_API_KEY', '')\n",
    "        return 'openai:qwen3'\n",
    "    else:\n",
    "        if 'OPENAI_BASE_URL' in os.environ:\n",
    "            del os.environ['OPENAI_BASE_URL']\n",
    "        os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', '')\n",
    "        return 'openai:gpt-4o-mini'\n",
    "\n",
    "agent = Agent(\n",
    "    model=get_model_config(MODEL),\n",
    "    deps_type=AgentContext,\n",
    "    system_prompt=\"\"\"You are a helpful assistant that helps users find and learn about California Landscape Metrics datasets.\n",
    "\n",
    "You have access to a search_datasets tool that can find relevant datasets based on user queries.\n",
    "\n",
    "When a user asks about a topic:\n",
    "1. Use the search_datasets tool to find the most relevant dataset\n",
    "2. Present the top result with key information (title, description, units)\n",
    "3. Answer any follow-up questions about the dataset metadata\n",
    "\n",
    "Be concise and helpful!\"\"\"\n",
    ")\n",
    "\n",
    "@agent.tool\n",
    "async def search_datasets(\n",
    "    ctx: RunContext[AgentContext],\n",
    "    query: str,\n",
    "    top_k: int = 3\n",
    ") -> dict:\n",
    "    \"\"\"Search for datasets related to the query.\"\"\"\n",
    "    with logfire.span(\"search_datasets\", query=query, top_k=top_k):\n",
    "        async with mcp_client:\n",
    "            result = await mcp_client.call_tool(\n",
    "                \"search_datasets\",\n",
    "                {\"query\": query, \"top_k\": top_k}\n",
    "            )\n",
    "            \n",
    "            data = result.data\n",
    "            if data.get('success') and data.get('datasets'):\n",
    "                best_dataset = data['datasets'][0]\n",
    "                ctx.deps.current_dataset = best_dataset\n",
    "                \n",
    "                logfire.info(\"dataset_found\", dataset_title=best_dataset.get('title'), query=query)\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'top_dataset': best_dataset,\n",
    "                    'alternatives': data['datasets'][1:] if len(data['datasets']) > 1 else [],\n",
    "                    'message': f\"Found: {best_dataset['title']}\"\n",
    "                }\n",
    "            else:\n",
    "                logfire.warning(\"no_datasets_found\", query=query)\n",
    "                return {\n",
    "                    'success': False,\n",
    "                    'message': 'No datasets found',\n",
    "                    'error': data.get('error', 'Unknown error')\n",
    "                }\n",
    "\n",
    "print(\"‚úì Agent created with automatic Logfire logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49b424-bc46-4b6e-9e86-bc3ca6cf43e2",
   "metadata": {},
   "source": [
    "### Step 5: Conversational Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b751ca-3712-49f2-b7d4-b5ce6488a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationalAgent:\n",
    "    def __init__(self, agent, model_name=\"openai\"):\n",
    "        self.agent = agent\n",
    "        self.model_name = model_name\n",
    "        self.history = []\n",
    "        # NRP Qwen3 needs longer timeout\n",
    "        self.default_timeout = 180 if model_name == \"nrp\" else 60\n",
    "        \n",
    "        logfire.info(\"session_started\", model_name=model_name, timeout=self.default_timeout)\n",
    "    \n",
    "    async def ask(self, question: str, timeout: int = None) -> str:\n",
    "        if timeout is None:\n",
    "            timeout = self.default_timeout\n",
    "        \n",
    "        with logfire.span(\"ask_question\", question=question[:100]):\n",
    "            if self.history:\n",
    "                full_input = \"\\n\".join(self.history) + f\"\\nUser: {question}\"\n",
    "            else:\n",
    "                full_input = f\"User: {question}\"\n",
    "            \n",
    "            try:\n",
    "                result = await asyncio.wait_for(\n",
    "                    self.agent.run(full_input, deps=AgentContext()),\n",
    "                    timeout=timeout\n",
    "                )\n",
    "                response = result.output if hasattr(result, 'output') else str(result)\n",
    "                \n",
    "                self.history.append(f\"User: {question}\")\n",
    "                self.history.append(f\"Assistant: {response}\")\n",
    "                \n",
    "                logfire.info(\"response_generated\", response_length=len(response))\n",
    "                return response\n",
    "                \n",
    "            except asyncio.TimeoutError:\n",
    "                logfire.error(\"timeout\", timeout=timeout)\n",
    "                return f\"Error: Request timed out after {timeout} seconds.\"\n",
    "            except Exception as e:\n",
    "                logfire.error(\"error\", error_type=type(e).__name__, error_message=str(e), exc_info=True)\n",
    "                return f\"Error: {type(e).__name__}: {str(e)}\"\n",
    "    \n",
    "    def clear_history(self):\n",
    "        self.history = []\n",
    "        logfire.info(\"history_cleared\")\n",
    "\n",
    "conv_agent = ConversationalAgent(agent, model_name=MODEL)\n",
    "print(f\"‚úì Conversational agent ready with {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452fbfb-cb8a-43eb-a69f-89543dad05eb",
   "metadata": {},
   "source": [
    "### Step 6: Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563b760-bcf1-42c2-9253-d1a1f2d7319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleChatInterface:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.messages = []\n",
    "        \n",
    "        self.output_area = widgets.VBox(\n",
    "            layout=widgets.Layout(border='1px solid #ddd', height='400px', overflow_y='auto', padding='10px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        self.input_box = widgets.Textarea(\n",
    "            placeholder='Ask about datasets...',\n",
    "            layout=widgets.Layout(width='100%', height='80px')\n",
    "        )\n",
    "        \n",
    "        self.send_button = widgets.Button(description='Send', button_style='primary')\n",
    "        self.clear_button = widgets.Button(description='Clear', button_style='warning')\n",
    "        self.status_label = widgets.HTML(value=\"‚úÖ Ready\")\n",
    "        \n",
    "        self.send_button.on_click(self.on_send)\n",
    "        self.clear_button.on_click(self.on_clear)\n",
    "        \n",
    "        button_row = widgets.HBox([self.send_button, self.clear_button, self.status_label])\n",
    "        self.interface = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ü§ñ Dataset Search Agent</h3>\"),\n",
    "            self.output_area,\n",
    "            self.input_box,\n",
    "            button_row\n",
    "        ])\n",
    "        \n",
    "        # self.add_message(\"Welcome! Ask me about California Landscape Metrics datasets.\", \"system\")\n",
    "        # Welcome message\n",
    "        self.add_message(\n",
    "            \"Welcome! I can help you find California Landscape Metrics datasets.\\n\\n\"\n",
    "            \"Try asking:\\n\"\n",
    "            \"‚Ä¢ Find datasets about carbon turnover\\n\"\n",
    "            \"‚Ä¢ What datasets are available for burn probability?\\n\"\n",
    "            \"‚Ä¢ Tell me about the units used in this dataset\\n\"\n",
    "            \"‚Ä¢ What's the description of this dataset?\",\n",
    "            \"system\"\n",
    "        )\n",
    "    \n",
    "    def add_message(self, text, role=\"user\"):\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        colors = {\n",
    "            \"user\": (\"#007bff\", \"üë§\", \"You\", \"#e7f3ff\"),\n",
    "            \"assistant\": (\"#28a745\", \"ü§ñ\", \"Agent\", \"#e8f5e9\"),\n",
    "            \"system\": (\"#6c757d\", \"‚ÑπÔ∏è\", \"System\", \"#f8f9fa\")\n",
    "        }\n",
    "        \n",
    "        color, icon, label, bg = colors.get(role, colors[\"system\"])\n",
    "        \n",
    "        message = widgets.HTML(\n",
    "            value=f\"\"\"<div style='margin: 10px 0; padding: 10px; background: {bg}; border-radius: 8px; border-left: 4px solid {color};'>\n",
    "                <div style='display: flex; justify-content: space-between; margin-bottom: 5px;'>\n",
    "                    <strong style='color: {color};'>{icon} {label}</strong>\n",
    "                    <span style='color: #999; font-size: 0.85em;'>{timestamp}</span>\n",
    "                </div>\n",
    "                <div style='white-space: pre-wrap;'>{text}</div>\n",
    "            </div>\"\"\"\n",
    "        )\n",
    "        \n",
    "        self.messages.append(message)\n",
    "        self.output_area.children = tuple(self.messages)\n",
    "    \n",
    "    def on_send(self, button):\n",
    "        question = self.input_box.value.strip()\n",
    "        if not question:\n",
    "            return\n",
    "        \n",
    "        self.add_message(question, \"user\")\n",
    "        self.input_box.value = \"\"\n",
    "        \n",
    "        self.send_button.disabled = True\n",
    "        self.input_box.disabled = True\n",
    "        self.status_label.value = \"<span style='color: orange;'>‚è≥ Thinking...</span>\"\n",
    "        \n",
    "        try:\n",
    "            response = asyncio.get_event_loop().run_until_complete(self.agent.ask(question))\n",
    "            self.add_message(response, \"assistant\")\n",
    "            self.status_label.value = \"<span style='color: green;'>‚úÖ Ready</span>\"\n",
    "        except Exception as e:\n",
    "            self.add_message(f\"Error: {str(e)}\", \"system\")\n",
    "            self.status_label.value = \"<span style='color: red;'>‚ùå Error</span>\"\n",
    "        finally:\n",
    "            self.send_button.disabled = False\n",
    "            self.input_box.disabled = False\n",
    "    \n",
    "    def on_clear(self, button):\n",
    "        self.messages = []\n",
    "        self.agent.clear_history()\n",
    "        self.output_area.children = tuple(self.messages)\n",
    "        self.add_message(\"Chat cleared!\", \"system\")\n",
    "    \n",
    "    def display(self):\n",
    "        clear_output(wait=True)\n",
    "        display(self.interface)\n",
    "\n",
    "print(\"‚úì Chat interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241167e5-9585-4734-b434-cc7f5d1cbfc9",
   "metadata": {},
   "source": [
    "### Step 7: Launch Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657266a-bf01-4cf1-91aa-72fb9dda52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = SimpleChatInterface(conv_agent)\n",
    "chat.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d9f08-b5ff-4f6b-b29f-1bb6cf2b8807",
   "metadata": {},
   "source": [
    "### Step 8: View Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46615898-f4c1-4f6c-83d9-d1a8a44486cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfire.info(\"setup_complete\", message=\"Visit https://logfire.pydantic.dev to view all logs\")\n",
    "print(\"‚úì Setup complete!\")\n",
    "print(\"\\nüìä View your logs at: https://logfire.pydantic.dev\")\n",
    "print(\"\\nAll CLM-MCP communications are automatically logged:\")\n",
    "print(\"  ‚Ä¢ Dataset searches\")\n",
    "print(\"  ‚Ä¢ Agent responses\")\n",
    "print(\"  ‚Ä¢ Errors and timeouts\")\n",
    "print(\"  ‚Ä¢ Performance metrics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
